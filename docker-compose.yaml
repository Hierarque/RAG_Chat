services:
  ollama:
    build:
      context: .
      dockerfile: ./ollama/Dockerfile
    image: ollama
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - .llms/:/root/.ollama 
    stdin_open: true
    tty: true

  # open-webui:
  #     build:
  #       context: .
  #       args:
  #         OLLAMA_BASE_URL: '/ollama'
  #       dockerfile: ./open-webUI/Dockerfile
  #     image: ghcr.io/open-webui/open-webui:${WEBUI_DOCKER_TAG-main}
  #     container_name: open-webui
  #     volumes:
  #       - ./open-webUI:/app/backend/data
  #     depends_on:
  #       - ollama
  #     ports:
  #       - ${OPEN_WEBUI_PORT-3000}:8080
  #     environment:
  #       - 'OLLAMA_BASE_URL=http://ollama:11434'
  #       - 'WEBUI_SECRET_KEY='
  #     extra_hosts:
  #       - host.docker.internal:host-gateway
  #     restart: unless-stopped
  rag:
      build:
        context: ./rag
        dockerfile: Dockerfile
      container_name: RAG
      volumes:
        - ./rag/python_cache:/app/.cache
      environment:
        - PDF_URL=your_url 
        - PYTHONUSERBASE=/app/.cache
      command: python main.py
      tty: true